{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ray in /home/alex/anaconda3/lib/python3.11/site-packages (2.9.3)\n","Requirement already satisfied: click>=7.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (8.0.4)\n","Requirement already satisfied: filelock in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (3.9.0)\n","Requirement already satisfied: jsonschema in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (4.17.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (1.0.3)\n","Requirement already satisfied: packaging in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (23.1)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (5.26.0)\n","Requirement already satisfied: pyyaml in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (6.0)\n","Requirement already satisfied: aiosignal in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (1.2.0)\n","Requirement already satisfied: frozenlist in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (1.3.3)\n","Requirement already satisfied: requests in /home/alex/anaconda3/lib/python3.11/site-packages (from ray) (2.31.0)\n","Requirement already satisfied: attrs>=17.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jsonschema->ray) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jsonschema->ray) (0.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests->ray) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests->ray) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests->ray) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests->ray) (2024.2.2)\n","\u001b[33mDEPRECATION: graphql-ws 0.3.0 has a non-standard dependency specifier graphql-core>=2.0<3. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of graphql-ws or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ray"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:47:02.840731Z","iopub.status.busy":"2024-03-18T10:47:02.840365Z","iopub.status.idle":"2024-03-18T10:47:16.042404Z","shell.execute_reply":"2024-03-18T10:47:16.041200Z","shell.execute_reply.started":"2024-03-18T10:47:02.840707Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: captum in /home/alex/anaconda3/lib/python3.11/site-packages (0.7.0)\n","Requirement already satisfied: matplotlib in /home/alex/anaconda3/lib/python3.11/site-packages (from captum) (3.7.2)\n","Requirement already satisfied: numpy in /home/alex/anaconda3/lib/python3.11/site-packages (from captum) (1.24.3)\n","Requirement already satisfied: torch>=1.6 in /home/alex/anaconda3/lib/python3.11/site-packages (from captum) (2.2.1)\n","Requirement already satisfied: tqdm in /home/alex/anaconda3/lib/python3.11/site-packages (from captum) (4.65.0)\n","Requirement already satisfied: filelock in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (3.9.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (4.10.0)\n","Requirement already satisfied: sympy in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (1.11.1)\n","Requirement already satisfied: networkx in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (3.1)\n","Requirement already satisfied: jinja2 in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.6->captum) (2023.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (1.0.5)\n","Requirement already satisfied: cycler>=0.10 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/alex/anaconda3/lib/python3.11/site-packages (from matplotlib->captum) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6->captum) (2.1.1)\n","Requirement already satisfied: mpmath>=0.19 in /home/alex/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","\u001b[33mDEPRECATION: graphql-ws 0.3.0 has a non-standard dependency specifier graphql-core>=2.0<3. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of graphql-ws or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: ax-platform in /home/alex/anaconda3/lib/python3.11/site-packages (0.3.6)\n","Requirement already satisfied: botorch==0.9.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (0.9.5)\n","Requirement already satisfied: jinja2 in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (3.1.2)\n","Requirement already satisfied: pandas in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (2.0.3)\n","Requirement already satisfied: scipy in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (1.11.1)\n","Requirement already satisfied: scikit-learn in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (1.3.0)\n","Requirement already satisfied: ipywidgets in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (8.0.4)\n","Collecting plotly>=5.12.0 (from ax-platform)\n","  Obtaining dependency information for plotly>=5.12.0 from https://files.pythonhosted.org/packages/00/4e/6258fc3b26f1f7abd1b2e75b1e9e4f12f13584136e2e1549f995ff4c6b7b/plotly-5.20.0-py3-none-any.whl.metadata\n","  Downloading plotly-5.20.0-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: typeguard in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (2.13.3)\n","Requirement already satisfied: pyre-extensions in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (0.0.30)\n","Requirement already satisfied: multipledispatch in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (0.6.0)\n","Requirement already satisfied: torch>=1.13.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (2.2.1)\n","Requirement already satisfied: pyro-ppl>=1.8.4 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (1.8.6)\n","Requirement already satisfied: gpytorch==1.11 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (1.11)\n","Requirement already satisfied: linear-operator==0.5.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (0.5.1)\n","Requirement already satisfied: jaxtyping>=0.2.9 in /home/alex/anaconda3/lib/python3.11/site-packages (from linear-operator==0.5.1->botorch==0.9.5->ax-platform) (0.2.25)\n","Requirement already satisfied: tenacity>=6.2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (8.2.2)\n","Requirement already satisfied: packaging in /home/alex/anaconda3/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (23.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (6.25.0)\n","Requirement already satisfied: ipython>=6.1.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (8.15.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (4.0.5)\n","Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (3.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jinja2->ax-platform) (2.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (1.24.3)\n","Requirement already satisfied: typing-inspect in /home/alex/anaconda3/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (0.9.0)\n","Requirement already satisfied: typing-extensions in /home/alex/anaconda3/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (4.10.0)\n","Requirement already satisfied: joblib>=1.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from scikit-learn->ax-platform) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from scikit-learn->ax-platform) (2.2.0)\n","Requirement already satisfied: comm>=0.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (0.1.2)\n","Requirement already satisfied: debugpy>=1.6.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (1.6.7)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (7.4.9)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (5.3.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (0.1.6)\n","Requirement already satisfied: nest-asyncio in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (1.5.6)\n","Requirement already satisfied: psutil in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (5.9.0)\n","Requirement already satisfied: pyzmq>=20 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (23.2.0)\n","Requirement already satisfied: tornado>=6.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (6.3.2)\n","Requirement already satisfied: backcall in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.2.0)\n","Requirement already satisfied: decorator in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.18.1)\n","Requirement already satisfied: pickleshare in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (3.0.36)\n","Requirement already satisfied: pygments>=2.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (2.15.1)\n","Requirement already satisfied: stack-data in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (4.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (3.3.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (0.1.2)\n","Requirement already satisfied: tqdm>=4.36 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (4.65.0)\n","Requirement already satisfied: six>=1.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ax-platform) (1.16.0)\n","Requirement already satisfied: filelock in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (3.9.0)\n","Requirement already satisfied: sympy in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (1.11.1)\n","Requirement already satisfied: networkx in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (3.1)\n","Requirement already satisfied: fsspec in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (2023.4.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from typing-inspect->pyre-extensions->ax-platform) (1.0.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->ax-platform) (0.8.3)\n","Requirement already satisfied: entrypoints in /home/alex/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ax-platform) (0.4)\n","Requirement already satisfied: platformdirs>=2.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->ax-platform) (3.10.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->ax-platform) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/alex/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.5)\n","Requirement already satisfied: executing in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (0.8.3)\n","Requirement already satisfied: asttokens in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (2.0.5)\n","Requirement already satisfied: pure-eval in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /home/alex/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13.1->botorch==0.9.5->ax-platform) (1.3.0)\n","Downloading plotly-5.20.0-py3-none-any.whl (15.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h\u001b[33mDEPRECATION: graphql-ws 0.3.0 has a non-standard dependency specifier graphql-core>=2.0<3. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of graphql-ws or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: plotly\n","  Attempting uninstall: plotly\n","    Found existing installation: plotly 5.9.0\n","    Uninstalling plotly-5.9.0:\n","      Successfully uninstalled plotly-5.9.0\n","Successfully installed plotly-5.20.0\n"]}],"source":["!pip install captum\n","\n","!pip install ax-platform"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:43.952156Z","iopub.status.busy":"2024-03-18T10:07:43.951603Z","iopub.status.idle":"2024-03-18T10:07:43.958795Z","shell.execute_reply":"2024-03-18T10:07:43.957903Z","shell.execute_reply.started":"2024-03-18T10:07:43.952124Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","# import ray\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_score"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:43.960333Z","iopub.status.busy":"2024-03-18T10:07:43.959962Z","iopub.status.idle":"2024-03-18T10:07:43.972117Z","shell.execute_reply":"2024-03-18T10:07:43.971252Z","shell.execute_reply.started":"2024-03-18T10:07:43.960302Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:43.975254Z","iopub.status.busy":"2024-03-18T10:07:43.974623Z","iopub.status.idle":"2024-03-18T10:07:43.984178Z","shell.execute_reply":"2024-03-18T10:07:43.983373Z","shell.execute_reply.started":"2024-03-18T10:07:43.975208Z"},"trusted":true},"outputs":[],"source":["# Defining Constants\n","DATA_PATH = \"./data/\"\n","labels_train_path = DATA_PATH + \"labels_train.csv\"\n","sample_path = DATA_PATH + \"sample.csv\"\n","seqs_test_path = DATA_PATH + \"seqs_test.csv\"\n","seqs_train_path = DATA_PATH + \"seqs_train.csv\"\n","train_path = DATA_PATH + \"train\"\n","test_path = DATA_PATH + \"test\"\n","\n","# Amino acid mapping\n","amino_acid_mapping = {\n","    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,\n","    'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,\n","    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,\n","    'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,\n","    'X': 20,  \n","    'B': 21,  \n","    'Z': 22,  \n","    'J': 23, \n","    '-': 24,  \n","}\n","\n","sec_struct_mapping = {'H': 0, 'E': 1, 'C': 2}"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:00:00.594964Z","iopub.status.busy":"2024-03-18T10:00:00.594343Z","iopub.status.idle":"2024-03-18T10:00:00.606308Z","shell.execute_reply":"2024-03-18T10:00:00.605204Z","shell.execute_reply.started":"2024-03-18T10:00:00.594932Z"}},"source":["Processes the input data from the csv files and uses one-hot encoding to encode the sequences. The pssm profiles are normalized for uniformity and labels if present, are just loaded into a dataframe."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:43.985749Z","iopub.status.busy":"2024-03-18T10:07:43.985440Z","iopub.status.idle":"2024-03-18T10:07:44.003542Z","shell.execute_reply":"2024-03-18T10:07:44.002642Z","shell.execute_reply.started":"2024-03-18T10:07:43.985725Z"},"trusted":true},"outputs":[],"source":["class DataProcessing(Dataset):\n","    def __init__(self, csv_file, train_dir, label_file=None, normalize_method='min-max'):\n","\n","        # Load the sequences\n","        self.seqs = pd.read_csv(csv_file)\n","\n","        # Load the data from the directory\n","        self.protein_data = {}\n","        for filename in os.listdir(train_dir):\n","            if filename.endswith(\".csv\"):  # Check if the file is a CSV\n","                protein_id = re.split(r'_train|_test', filename)[0]\n","                self.protein_data[protein_id] = pd.read_csv(os.path.join(train_dir, filename))\n","\n","        # Load the labels (for training data)\n","        if label_file:\n","            self.labels = pd.read_csv(label_file)\n","        else:\n","            self.labels = None\n","\n","        # Perform amino acid mapping\n","        self.amino_acid_mapping = amino_acid_mapping\n","        self.normalize_method = normalize_method\n","\n","    def seq_encode(self, sequence):\n","        #Perform one-hot encoding\n","        encoded_sequence = np.zeros((len(sequence), len(self.amino_acid_mapping)), dtype=int)\n","        for i, amino_acid in enumerate(sequence):\n","            # Set 'X' for unknown amino acids\n","            index = self.amino_acid_mapping.get(amino_acid, self.amino_acid_mapping['X'])\n","            encoded_sequence[i, index] = 1\n","        return encoded_sequence\n","\n","    def normalize_pssm(self, pssm):\n","        numeric_columns = pssm[:, 2:]\n","        try:\n","            pssm_numeric = numeric_columns.astype(np.float32)\n","        except ValueError as e:\n","            raise ValueError(f\"Error converting PSSM to float: {e}\")\n","\n","        if self.normalize_method == 'min-max':\n","            # Min-Max normalization\n","            pssm_min = pssm_numeric.min(axis=0)\n","            pssm_max = pssm_numeric.max(axis=0)\n","            # Ensuring no zero division error\n","            pssm_range = np.where(pssm_max - pssm_min == 0, 1, pssm_max - pssm_min)\n","            normalized_pssm = (pssm_numeric - pssm_min) / pssm_range\n","        elif self.normalize_method == 'z-score':\n","            # Z-Score normalization\n","            pssm_mean = pssm_numeric.mean(axis=0)\n","            pssm_std = pssm_numeric.std(axis=0)\n","            # Avoid division by zero\n","            pssm_std = np.where(pssm_std == 0, 1, pssm_std)\n","            normalized_pssm = (pssm_numeric - pssm_mean) / pssm_std\n","        else:\n","            # If no normalization method provided, return the original PSSM\n","            normalized_pssm = pssm_numeric\n","\n","        return normalized_pssm\n","\n","    def __len__(self):\n","        return len(self.seqs)\n","\n","    def __getitem__(self, idx):\n","        protein_id = self.seqs.iloc[idx]['PDB_ID']\n","        sequence = self.seqs.iloc[idx]['SEQUENCE']\n","        encoded_sequence = self.seq_encode(sequence)  # Encoding the sequence\n","        pssm = self.protein_data[protein_id].values \n","        normalized_pssm = self.normalize_pssm(pssm) \n","\n","        if self.labels is not None:\n","            label_seq = self.labels.iloc[idx]['SEC_STRUCT']\n","            label_numeric = [sec_struct_mapping[char] for char in label_seq]\n","            label_tensor = torch.tensor(label_numeric, dtype=torch.long)\n","            return (\n","                protein_id,\n","                torch.tensor(encoded_sequence, dtype=torch.float32),\n","                torch.tensor(normalized_pssm, dtype=torch.float32),\n","                label_tensor\n","            )\n","\n","        return (\n","            protein_id,\n","            torch.tensor(encoded_sequence, dtype=torch.float32),\n","            torch.tensor(normalized_pssm, dtype=torch.float32)\n","        )"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:44.004783Z","iopub.status.busy":"2024-03-18T10:07:44.004524Z","iopub.status.idle":"2024-03-18T10:07:44.017052Z","shell.execute_reply":"2024-03-18T10:07:44.016215Z","shell.execute_reply.started":"2024-03-18T10:07:44.004760Z"},"trusted":true},"outputs":[],"source":["def collate(batch):\n","    _, sequences, pssms, labels_list = zip(*batch)  # Unzip the batch\n","    # Pad sequences and PSSMs to avoid shape mismatch\n","    sequences_padded = pad_sequence([seq.clone().detach() for seq in sequences], batch_first=True)\n","    pssms_padded = pad_sequence([pssm.clone().detach() for pssm in pssms], batch_first=True)\n","    if labels_list[0] is not None:  # Check if labels exist\n","        labels_padded = pad_sequence([label.clone().detach() for label in labels_list], batch_first=True)\n","    else:\n","        labels_padded = None\n","    return sequences_padded, pssms_padded, labels_padded\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:07:44.018572Z","iopub.status.busy":"2024-03-18T10:07:44.018204Z","iopub.status.idle":"2024-03-18T10:07:44.029898Z","shell.execute_reply":"2024-03-18T10:07:44.028997Z","shell.execute_reply.started":"2024-03-18T10:07:44.018538Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(\n","            self,\n","            num_classes,\n","            input_channels,\n","            hidden_layers_number,\n","            dropout_rate\n","    ):\n","        super(CNN, self).__init__()\n","        self.hidden_layers = self.get_hidden_layers_size(hidden_layers_number)\n","        self.dropout_rate = dropout_rate\n","        self.convs = nn.ModuleList()\n","        in_channels = input_channels\n","        for out_channels in self.hidden_layers:\n","            self.convs.append(\n","                nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n","            )\n","            in_channels = out_channels \n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.final_conv = nn.Conv1d(in_channels=self.hidden_layers[-1], out_channels=num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        for conv in self.convs:\n","            x = F.relu(conv(x))\n","            x = self.dropout(x)  \n","        x = self.final_conv(x)\n","        x = x.transpose(1, 2)\n","        return x\n","\n","    def get_hidden_layers_size(self, number):\n","        hidden_layers_configs = {\n","            1: [64],  \n","            2: [64, 128],  \n","            3: [64, 128, 256],  \n","            4: [64, 128, 256, 512],  \n","            5: [64, 128, 256, 512, 1024]  \n","        }\n","        return hidden_layers_configs[number]"]},{"cell_type":"markdown","metadata":{},"source":["The train, test and validate model functions are being declared below."]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score\n","\n","def train_model(model, criterion, optimizer, train_dataloader, num_epochs, input_type, log_precision=False):\n","    losses = []\n","    for epoch in range(num_epochs):\n","        model.train()  \n","        epoch_losses = []\n","        print(\"Compiler in the train_model\")\n","        for sequences, pssms, labels in train_dataloader:\n","            if input_type == \"pssms\":\n","                inputs = pssms.permute(0, 2, 1) \n","            else:\n","                inputs = sequences.permute(0, 2, 1)  \n","\n","            inputs = inputs\n","            labels = labels\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs.transpose(1, 2), labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            epoch_losses.append(loss.item())\n","\n","        losses.append(epoch_losses)\n","        \n","        predictions, labels = [], []\n","        model.eval() \n","        with torch.no_grad():\n","            for sequences, pssms, labels in train_dataloader:\n","                inputs = pssms.permute(0, 2, 1)\n","                labels = labels\n","                outputs = model(inputs)\n","                print(\"predicting...\")\n","                _, predicted = torch.max(outputs.data, 2)\n","                #predictions.extend(predicted.view(-1).cpu().numpy())\n","                predicted_list = predicted.view(-1).cpu().numpy().tolist()\n","                labels_list = labels.view(-1).cpu().numpy().tolist()\n","                #predictions.extend(predicted_list)\n","                #labels.extend(labels_list)\n","        \n","        # Calculate precision\n","        epoch_precision = precision_score(labels, predictions, average='macro')\n","    \n","        print(f'Epoch {epoch+1}/{num_epochs}, Precision: {epoch_precision:.4f}')\n","    \n","    return losses\n","\n","def plot_loss_curve(losses):\n","    for fold, loss in enumerate(losses):\n","        plt.plot(loss, label=f'Epoch {fold + 1}')\n","    plt.title('Training Loss Curve')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["def validate_model(model, criterion, val_dataloader, input_type):\n","    model.eval()  \n","    predictions, labels = [], []\n","\n","\n","    with torch.no_grad():\n","        for sequences, pssms, labels in val_dataloader:\n","            if input_type == \"pssms\":\n","                inputs = pssms.permute(0, 2, 1)  \n","            else:\n","                inputs = sequences.permute(0, 2, 1)  \n","\n","            inputs = inputs\n","            labels = labels\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 2)\n","            predictions.extend(predicted.view(-1).cpu().numpy())\n","            labels.extend(labels.view(-1).cpu().numpy())\n","\n","    precision = precision_score(labels, predictions, average='macro')\n","    return precision"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def test_model(model, test_dataset, output_file, input_type):\n","    model.eval()  \n","    predictions = []\n","\n","    with torch.no_grad():\n","        for i in range(len(test_dataset)):  \n","            pdb_id, sequence, pssm = test_dataset[i] \n","            if input_type == \"pssms\":\n","                input = pssm.unsqueeze(0).permute(0, 2, 1)  # Adjust dimensions to [1, features, seq_len]\n","            else:\n","                input = sequence.unsqueeze(0).permute(0, 2, 1)  # Adjust dimensions to [1, features, seq_len]\n","            \n","            # Make a prediction\n","            outputs = model(input)\n","            _, predicted = torch.max(outputs, 2)  # Get the index of max log-probability\n","            # Process the predictions\n","            seq_len = pssm.shape[0]  \n","            for j in range(seq_len):\n","                residue_id = f\"{pdb_id}_{j + 1}\"  \n","                structure_label = ['H', 'E', 'C'][predicted[0, j].item()] \n","                predictions.append([residue_id, structure_label])\n","\n","    # Write predictions to a CSV for submission\n","    pd.DataFrame(predictions, columns=['ID', 'STRUCTURE']).to_csv(output_file, index=False)\n","    print(f'Submission file saved to {output_file}')"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-03-18T10:01:47.952340Z","iopub.status.busy":"2024-03-18T10:01:47.951646Z","iopub.status.idle":"2024-03-18T10:01:47.958013Z","shell.execute_reply":"2024-03-18T10:01:47.956805Z","shell.execute_reply.started":"2024-03-18T10:01:47.952305Z"}},"source":["The best optimizer is given as input accordingly and the optimizer function defines the \"optimizer\" accordingly to avoid hassle."]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["def get_optimizer(optimizer_type, model, lr, weight_decay):\n","    if optimizer_type == \"adam\":\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    elif optimizer_type == \"sgd\":\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","    elif optimizer_type == \"rmsprop\":\n","        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    else:\n","        raise ValueError(\"Optimizer not known\")\n","    return optimizer"]},{"cell_type":"markdown","metadata":{},"source":["HYPER-PARAMETER TUNING\n","\n","\n","The AX-hyper parameter tuning is used here to improve the accuracy of the model. Ry-tune couldnt be used due to some package version mis-match issues.\n","\n","\n","The below function is to train the model after extracting the best parameters."]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","\n","def train_and_val(\n","        num_folds,\n","        input_type,\n","        lr,\n","        batch_size,\n","        hidden_layers,\n","        dropout_rate,\n","        weight_decay,\n","        optimizer_type,\n","        normalization,\n","        num_epochs,\n","):\n","    train_dataset = DataProcessing(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path,\n","                                   normalize_method=normalization)\n","\n","    kf = KFold(n_splits=num_folds)   # Initialize KFold\n","    full_dataset_list = list(range(len(train_dataset)))  # Converting dataset to a list\n","    fold_precisions = []     # Cross-validation loop\n","    \n","    # List to store loss values during training\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(full_dataset_list)):\n","        print(f\"Fold {fold + 1}/{num_folds}\")\n","        # Split dataset to training and evaluation set\n","        train_subsampler = torch.utils.data.SubsetRandomSampler(train_index)\n","        val_subsampler = torch.utils.data.SubsetRandomSampler(val_index)\n","        # Create data-loaders \n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_subsampler, collate_fn=collate)\n","        val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_subsampler, collate_fn=collate)\n","        # Model Initialization\n","        if input_type == \"pssms\":\n","            input_channels = 20\n","        else:\n","            input_channels = 25\n","        model = CNN(\n","            num_classes=3,\n","            input_channels=input_channels,\n","            hidden_layers_number=hidden_layers,\n","            dropout_rate=dropout_rate\n","        )\n","        \n","        # Loss function and optimizer\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = get_optimizer(optimizer_type, model, lr, weight_decay)\n","\n","        # Train and validate the model\n","        print(\"Training the model...\")\n","        train_model(model, criterion, optimizer, train_loader, num_epochs, input_type)\n","        \n","        print(\"Validating the model...\")\n","        fold_precision = validate_model(model, criterion, val_loader, input_type)\n","        fold_precisions.append(fold_precision)\n","\n","    # Calculate average loss and accuracy across all folds created\n","    avg_precisions = sum(fold_precisions) / num_folds\n","    print(f\"Average Precisions: {avg_precisions:.4f}\")\n","\n","    \n","    return avg_precisions\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["The train_test_entire trains and tests the entire data after the model is completely ready with thye best parameters"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def train_test_entire(\n","        input_type,\n","        lr,\n","        batch_size,\n","        hidden_layers,\n","        dropout_rate,\n","        weight_decay,\n","        optimizer_type,\n","        normalization,\n","        num_epochs,\n","        output_file\n","):\n","    train_dataset = DataProcessing(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path,\n","                                   normalize_method=normalization)\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)\n","    test_dataset = DataProcessing(csv_file=seqs_test_path, train_dir=test_path, normalize_method=normalization)\n","    if input_type == \"pssms\":\n","        input_channels = 20\n","    else:\n","        input_channels = 25\n","    model = CNN(\n","        num_classes=3,\n","        input_channels=input_channels,\n","        hidden_layers_number=hidden_layers,\n","        dropout_rate=dropout_rate\n","    )\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = get_optimizer(optimizer_type, model, lr, weight_decay)\n","    print(\"Training model...\")\n","    train_model(model, criterion, optimizer, train_dataloader, num_epochs, input_type)\n","    print(\"Testing model...\")\n","    test_model(model, test_dataset, output_file, input_type)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["from ax.service.ax_client import AxClient\n","from ax.service.utils.instantiation import ObjectiveProperties\n","import os\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch._tensor import Tensor\n","from ax.service.ax_client import AxClient, ObjectiveProperties\n","from ax.service.utils.report_utils import exp_to_df\n","from ax.utils.notebook.plotting import init_notebook_plotting, render\n","from ax.utils.tutorials.cnn_utils import evaluate, load_mnist, train"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Use GPU to speed-up model training , validation and testing"]},{"cell_type":"markdown","metadata":{},"source":["The train_hyper function is used to train the model after getting the best parameters."]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def train_hyper(parameterization):\n","    avg_precision, epoch = train_and_val(\n","                                num_folds=3,\n","                                input_type=\"pssms\",  # Can give \"sequence\" or \"pssms\" as inputs\n","                                lr=parameterization[\"lr\"],\n","                                batch_size=parameterization[\"batch_size\"],\n","                                hidden_layers=parameterization.get(\"hidden_layers\", 3),\n","                                dropout_rate=parameterization.get(\"dropout_rate\", 0.5),\n","                                weight_decay=parameterization.get(\"weight_decay\", 0),\n","                                optimizer_type=parameterization[\"optimizer\"],\n","                                normalization=parameterization[\"normalization\"],\n","                                num_epochs=parameterization.get(\"epochs\", 1),\n","                            )\n","    print(f\"Accuracy: {avg_precision}, Epoch: {epoch}\")\n","    return {\"precision\": avg_precision}\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, the AX experiment is being set-up to run repetitive trials for finding the best parameters. The parameters needed for the model optimization are passed to the training function and the model is trained every-time giving a different value for eachparam every time. Finally after training, the best parameter is chosen and the model can be trained with the best parameter to yield better results while testing."]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[INFO 03-18 11:56:24] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n","[INFO 03-18 11:56:24] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-18 11:56:24] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_layers. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`is_ordered` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n","\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`sort_values` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n","\n","[INFO 03-18 11:56:24] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter dropout_rate. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-18 11:56:24] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter weight_decay. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-18 11:56:24] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[0.0001, 0.01], log_scale=True), FixedParameter(name='batch_size', parameter_type=INT, value=4), ChoiceParameter(name='hidden_layers', parameter_type=INT, values=[4, 5], is_ordered=True, sort_values=True), RangeParameter(name='dropout_rate', parameter_type=FLOAT, range=[0.0, 0.7]), RangeParameter(name='weight_decay', parameter_type=FLOAT, range=[0.0, 0.1]), FixedParameter(name='epochs', parameter_type=INT, value=10), FixedParameter(name='optimizer', parameter_type=STRING, value='rmsprop'), FixedParameter(name='normalization', parameter_type=STRING, value='min-max')], parameter_constraints=[]).\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there are more ordered parameters than there are categories for the unordered categorical parameters.\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=4 num_trials=None use_batch_trials=False\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=8\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=8\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n","[INFO 03-18 11:56:24] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 8 trials, BoTorch for subsequent trials]). Iterations after 8 will take longer to generate due to model-fitting.\n","[WARNING 03-18 11:56:24] ax.modelbridge.generation_node: Even though this node is not flagged for generation of unlimited trials, there are no generation blocking criterion, therefore, unlimited trials will be generated.\n","[INFO 03-18 11:56:24] ax.service.ax_client: Generated new trial 0 with parameters {'lr': 0.001033, 'hidden_layers': 5, 'dropout_rate': 0.022464, 'weight_decay': 0.000192, 'batch_size': 4, 'epochs': 10, 'optimizer': 'rmsprop', 'normalization': 'min-max'}.\n"]},{"name":"stdout","output_type":"stream","text":["Fold 1/3\n","Training the model...\n","Compiler in the train_model\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n","predicting...\n"]},{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [2, 0]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):  \n\u001b[1;32m     21\u001b[0m     params, trial_index \u001b[38;5;241m=\u001b[39m ax_client\u001b[38;5;241m.\u001b[39mget_next_trial()\n\u001b[0;32m---> 22\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m train_hyper(params)\n\u001b[1;32m     23\u001b[0m     ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(trial_index\u001b[38;5;241m=\u001b[39mtrial_index, raw_data\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Fetching the best parameters\u001b[39;00m\n","Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mtrain_hyper\u001b[0;34m(parameterization)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_hyper\u001b[39m(parameterization):\n\u001b[0;32m----> 2\u001b[0m     avg_precision, epoch \u001b[38;5;241m=\u001b[39m train_and_val(\n\u001b[1;32m      3\u001b[0m                                 num_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                 input_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpssms\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Can give \"sequence\" or \"pssms\" as inputs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                                 lr\u001b[38;5;241m=\u001b[39mparameterization[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m                                 batch_size\u001b[38;5;241m=\u001b[39mparameterization[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m                                 hidden_layers\u001b[38;5;241m=\u001b[39mparameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      8\u001b[0m                                 dropout_rate\u001b[38;5;241m=\u001b[39mparameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m      9\u001b[0m                                 weight_decay\u001b[38;5;241m=\u001b[39mparameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     10\u001b[0m                                 optimizer_type\u001b[38;5;241m=\u001b[39mparameterization[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m                                 normalization\u001b[38;5;241m=\u001b[39mparameterization[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalization\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m                                 num_epochs\u001b[38;5;241m=\u001b[39mparameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     13\u001b[0m                             )\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_precision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: avg_precision}\n","Cell \u001b[0;32mIn[17], line 51\u001b[0m, in \u001b[0;36mtrain_and_val\u001b[0;34m(num_folds, input_type, lr, batch_size, hidden_layers, dropout_rate, weight_decay, optimizer_type, normalization, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Train and validate the model\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m train_model(model, criterion, optimizer, train_loader, num_epochs, input_type)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m fold_precision \u001b[38;5;241m=\u001b[39m validate_model(model, criterion, val_loader, input_type)\n","Cell \u001b[0;32mIn[13], line 45\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_dataloader, num_epochs, input_type, log_precision)\u001b[0m\n\u001b[1;32m     40\u001b[0m             labels_list \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;66;03m#predictions.extend(predicted_list)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;66;03m#labels.extend(labels_list)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Calculate precision\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     epoch_precision \u001b[38;5;241m=\u001b[39m precision_score(labels, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2127\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1971\u001b[0m     {\n\u001b[1;32m   1972\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1997\u001b[0m ):\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \n\u001b[1;32m   2000\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2127\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2128\u001b[0m         y_true,\n\u001b[1;32m   2129\u001b[0m         y_pred,\n\u001b[1;32m   2130\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   2131\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   2132\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   2133\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m   2134\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   2135\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   2136\u001b[0m     )\n\u001b[1;32m   2137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 0]"]}],"source":["# Setting up an Ax experiment\n","ax_client = AxClient(enforce_sequential_optimization=False)\n","ax_client.create_experiment(\n","    name=\"protein_model_experiment\",\n","    parameters=[\n","        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [0.0001, 0.01], \"log_scale\": True},\n","        {\"name\": \"batch_size\", \"type\": \"fixed\", \"value\": 4},\n","        {\"name\": \"hidden_layers\", \"type\": \"choice\", \"values\": [4, 5]},\n","        {\"name\": \"dropout_rate\", \"type\": \"range\", \"bounds\": [0.0, 0.7]},\n","        {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [0.0, 0.1]},\n","        {\"name\": \"epochs\", \"type\": \"fixed\", \"value\": 10},\n","        {\"name\": \"optimizer\", \"type\": \"fixed\", \"value\": \"rmsprop\"},  \n","        {\"name\": \"normalization\", \"type\": \"fixed\", \"value\": \"min-max\"},\n","\n","    ],\n","    objectives={\"precision\": ObjectiveProperties(minimize=False)}\n",")\n","\n","# Running the trials\n","for i in range(1):  \n","    params, trial_index = ax_client.get_next_trial()\n","    metrics = train_hyper(params)\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=metrics)\n","\n","# Fetching the best parameters\n","best_parameters, metrics = ax_client.get_best_parameters()\n","print(f'Best Parameters: {best_parameters}')\n","print(metrics)\n","best_metrics = metrics['objectives']\n","print(f'Best Precision: {best_metrics}')"]},{"cell_type":"markdown","metadata":{},"source":["Get the best parameters and train-validate (by calling the train_hyper function) the model again to increase the accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T10:44:45.145189Z","iopub.status.idle":"2024-03-18T10:44:45.145595Z","shell.execute_reply":"2024-03-18T10:44:45.145440Z","shell.execute_reply.started":"2024-03-18T10:44:45.145424Z"},"trusted":true},"outputs":[],"source":["train_and_val(\n","    num_folds=3,\n","    input_type=\"pssms\", \n","    lr=0.001,\n","    batch_size=4,\n","    hidden_layers=3,\n","    dropout_rate=0.233246,\n","    weight_decay=0.0,\n","    optimizer_type='rmsprop',\n","    normalization='min-max',\n","    num_epochs=10,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["After training and validating the model using the best parameters, test the test-data to predict the secondary protein structures of the given input."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T10:44:45.147273Z","iopub.status.idle":"2024-03-18T10:44:45.147728Z","shell.execute_reply":"2024-03-18T10:44:45.147506Z","shell.execute_reply.started":"2024-03-18T10:44:45.147487Z"},"trusted":true},"outputs":[],"source":["train_test_entire(\n","    input_type=\"pssms\",  # \"sequence\" or \"pssms\"\n","    lr=0.001,\n","    batch_size=4,\n","    hidden_layers=3,\n","    dropout_rate=0.5,\n","    weight_decay=0.0001,\n","    optimizer_type='sgd',\n","    normalization='min-max',\n","    num_epochs=10,\n","    output_file='./prediction.csv'\n"," )"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7709659,"sourceId":68978,"sourceType":"competition"},{"sourceId":166881460,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
