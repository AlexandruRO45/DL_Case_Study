{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:19.143398Z","iopub.status.busy":"2024-03-17T01:08:19.142935Z","iopub.status.idle":"2024-03-17T01:08:19.148758Z","shell.execute_reply":"2024-03-17T01:08:19.147835Z","shell.execute_reply.started":"2024-03-17T01:08:19.143352Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["# Imports & Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:19.150756Z","iopub.status.busy":"2024-03-17T01:08:19.150389Z","iopub.status.idle":"2024-03-17T01:08:35.421159Z","shell.execute_reply":"2024-03-17T01:08:35.420064Z","shell.execute_reply.started":"2024-03-17T01:08:19.150722Z"},"trusted":true},"outputs":[],"source":["!pip install -U ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.423121Z","iopub.status.busy":"2024-03-17T01:08:35.422737Z","iopub.status.idle":"2024-03-17T01:08:35.430426Z","shell.execute_reply":"2024-03-17T01:08:35.429538Z","shell.execute_reply.started":"2024-03-17T01:08:35.423085Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","\n","import numpy as np\n","import pandas as pd\n","import ray\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from ray import train as ray_train\n","from ray import tune\n","from ray.tune.schedulers import ASHAScheduler\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.432943Z","iopub.status.busy":"2024-03-17T01:08:35.432636Z","iopub.status.idle":"2024-03-17T01:08:35.488002Z","shell.execute_reply":"2024-03-17T01:08:35.487046Z","shell.execute_reply.started":"2024-03-17T01:08:35.432918Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f635a9cf-9b56-41c1-b423-38e13f72b067","_uuid":"83f50fc9-895b-4a81-8b08-f0da6d5fa4ac","collapsed":false,"execution":{"iopub.execute_input":"2024-03-17T01:08:35.489477Z","iopub.status.busy":"2024-03-17T01:08:35.489174Z","iopub.status.idle":"2024-03-17T01:08:35.500711Z","shell.execute_reply":"2024-03-17T01:08:35.499793Z","shell.execute_reply.started":"2024-03-17T01:08:35.489452Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Define Constants\n","\n","DATA_PATH = \"/kaggle/input/deep-learning-for-msc-202324/\"\n","labels_train_path = DATA_PATH + \"labels_train.csv\"\n","sample_path = DATA_PATH + \"sample.csv\"\n","seqs_test_path = DATA_PATH + \"seqs_test.csv\"\n","seqs_train_path = DATA_PATH + \"seqs_train.csv\"\n","train_path = DATA_PATH + \"train\"\n","test_path = DATA_PATH + \"test\"\n","\n","# Define a mapping from amino acid characters to integers\n","amino_acid_mapping = {\n","    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,\n","    'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,\n","    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,\n","    'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,\n","    'X': 20,  # Typically used for unknown amino acids\n","    'B': 21,  # Asparagine or Aspartic acid\n","    'Z': 22,  # Glutamine or Glutamic acid\n","    'J': 23,  # Leucine or Isoleucine\n","    '-': 24,  # Gap or padding\n","}\n","\n","sec_struct_mapping = {'H': 0, 'E': 1, 'C': 2}"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Class & Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32ac1407-65f5-4381-8c33-b42d88efd856","_uuid":"de446eba-91c9-4920-b48e-dee1f3657699","collapsed":false,"execution":{"iopub.execute_input":"2024-03-17T01:08:35.502328Z","iopub.status.busy":"2024-03-17T01:08:35.502067Z","iopub.status.idle":"2024-03-17T01:08:35.521182Z","shell.execute_reply":"2024-03-17T01:08:35.520362Z","shell.execute_reply.started":"2024-03-17T01:08:35.502298Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class ProteinDataset(Dataset):\n","    def __init__(self, csv_file, train_dir, label_file=None, normalize_method='min-max'):\n","\n","        # Load the sequences\n","        self.seqs = pd.read_csv(csv_file)\n","\n","        # Load the protein data from the directory\n","        self.protein_data = {}\n","        for filename in os.listdir(train_dir):\n","            if filename.endswith(\".csv\"):  # Check if the file is a CSV\n","                protein_id = re.split(r'_train|_test', filename)[0]\n","                self.protein_data[protein_id] = pd.read_csv(os.path.join(train_dir, filename))\n","\n","        # Load the labels, if provided\n","        if label_file:\n","            self.labels = pd.read_csv(label_file)\n","        else:\n","            self.labels = None\n","\n","        # Amino acid mapping\n","        self.amino_acid_mapping = amino_acid_mapping\n","        self.normalize_method = normalize_method\n","\n","    def encode_sequence(self, sequence):\n","        # Convert each amino acid in the sequence to a one-hot encoded vector\n","        encoded_sequence = np.zeros((len(sequence), len(self.amino_acid_mapping)), dtype=int)\n","        for i, amino_acid in enumerate(sequence):\n","            # Default to 'X' for unknown amino acids\n","            index = self.amino_acid_mapping.get(amino_acid, self.amino_acid_mapping['X'])\n","            encoded_sequence[i, index] = 1\n","        return encoded_sequence\n","\n","    def normalize_pssm(self, pssm):\n","        # Assuming the first two columns are non-numeric; adjust as necessary based on your actual data format\n","        numeric_columns = pssm[:, 2:]  # Adjust this if your numeric data starts from a different column\n","\n","        # Convert to floats\n","        try:\n","            pssm_numeric = numeric_columns.astype(np.float32)\n","        except ValueError as e:\n","            # Handle or log the error if needed\n","            raise ValueError(f\"Error converting PSSM to float: {e}\")\n","\n","        if self.normalize_method == 'min-max':\n","            # Min-Max normalization\n","            pssm_min = pssm_numeric.min(axis=0)\n","            pssm_max = pssm_numeric.max(axis=0)\n","            # Ensure no division by zero\n","            pssm_range = np.where(pssm_max - pssm_min == 0, 1, pssm_max - pssm_min)\n","            normalized_pssm = (pssm_numeric - pssm_min) / pssm_range\n","        elif self.normalize_method == 'z-score':\n","            # Z-Score normalization\n","            pssm_mean = pssm_numeric.mean(axis=0)\n","            pssm_std = pssm_numeric.std(axis=0)\n","            # Avoid division by zero\n","            pssm_std = np.where(pssm_std == 0, 1, pssm_std)\n","            normalized_pssm = (pssm_numeric - pssm_mean) / pssm_std\n","        else:\n","            # If no normalization method provided, return the original PSSM\n","            normalized_pssm = pssm_numeric\n","\n","        return normalized_pssm\n","\n","    def __len__(self):\n","        return len(self.seqs)\n","\n","    def __getitem__(self, idx):\n","        protein_id = self.seqs.iloc[idx]['PDB_ID']\n","        sequence = self.seqs.iloc[idx]['SEQUENCE']\n","        encoded_sequence = self.encode_sequence(sequence)  # Encode the sequence\n","        pssm = self.protein_data[protein_id].values  # Assuming you will process PSSM separately\n","        normalized_pssm = self.normalize_pssm(pssm)  # Ensure this is uncommented to use normalized PSSM\n","\n","        if self.labels is not None:\n","            label_seq = self.labels.iloc[idx]['SEC_STRUCT']\n","            label_numeric = [sec_struct_mapping[char] for char in label_seq]\n","            label_tensor = torch.tensor(label_numeric, dtype=torch.long)\n","            return (\n","                protein_id,\n","                torch.tensor(encoded_sequence, dtype=torch.float32),\n","                torch.tensor(normalized_pssm, dtype=torch.float32),\n","                label_tensor\n","            )\n","\n","        return (\n","            protein_id,\n","            torch.tensor(encoded_sequence, dtype=torch.float32),\n","            torch.tensor(normalized_pssm, dtype=torch.float32)\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.522315Z","iopub.status.busy":"2024-03-17T01:08:35.522080Z","iopub.status.idle":"2024-03-17T01:08:35.540330Z","shell.execute_reply":"2024-03-17T01:08:35.539581Z","shell.execute_reply.started":"2024-03-17T01:08:35.522286Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    _, sequences, pssms, labels_list = zip(*batch)  # Unzip the batch\n","\n","    # Pad sequences and PSSMs\n","    sequences_padded = pad_sequence([seq.clone().detach() for seq in sequences], batch_first=True)\n","\n","    pssms_padded = pad_sequence([pssm.clone().detach() for pssm in pssms], batch_first=True)\n","\n","    # Handling labels correctly\n","    if labels_list[0] is not None:  # Check if labels exist\n","        labels_padded = pad_sequence([label.clone().detach() for label in labels_list], batch_first=True)\n","\n","    else:\n","        labels_padded = None\n","\n","    return sequences_padded, pssms_padded, labels_padded\n"]},{"cell_type":"markdown","metadata":{},"source":["# Fully Convolutional Networks (FCNs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.541574Z","iopub.status.busy":"2024-03-17T01:08:35.541295Z","iopub.status.idle":"2024-03-17T01:08:35.559914Z","shell.execute_reply":"2024-03-17T01:08:35.559189Z","shell.execute_reply.started":"2024-03-17T01:08:35.541551Z"},"trusted":true},"outputs":[],"source":["class FullyConvolutionalProteinModel(nn.Module):\n","    def __init__(\n","            self,\n","            num_classes,\n","            input_channels,\n","            hidden_layers_number,\n","            dropout_rate\n","    ):\n","        super(FullyConvolutionalProteinModel, self).__init__()\n","\n","        # List of out_channels for each hidden layer\n","        self.hidden_layers = self.get_hidden_layers_size(hidden_layers_number)\n","        self.dropout_rate = dropout_rate\n","\n","        # Creating convolutional layers dynamically based on 'hidden_layers' input\n","        self.convs = nn.ModuleList()\n","        in_channels = input_channels\n","        for out_channels in self.hidden_layers:\n","            self.convs.append(\n","                nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n","            )\n","            in_channels = out_channels  # Next layer's in_channels is current layer's out_channels\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        # Final layer that maps to the number of classes\n","        # The last item of hidden_layers list is used as in_channels here\n","        self.final_conv = nn.Conv1d(in_channels=self.hidden_layers[-1], out_channels=num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Apply convolutional layers with activation functions and dropout\n","        for conv in self.convs:\n","            x = F.relu(conv(x))\n","            x = self.dropout(x)  # Apply dropout after activation\n","\n","        # Apply final convolutional layer - no activation, as CrossEntropyLoss includes it\n","        x = self.final_conv(x)\n","\n","        # No softmax here, as nn.CrossEntropyLoss applies it internally.\n","        # Transpose the output to match [batch_size, sequence_length, num_classes]\n","        x = x.transpose(1, 2)\n","\n","        return x\n","\n","    def get_hidden_layers_size(self, number):\n","        hidden_layers_configs = {\n","            1: [64],  # one layer with 64 channels\n","            2: [64, 128],  # two layers with 64 and 128 channels\n","            3: [64, 128, 256],  # three layers\n","            4: [64, 128, 256, 512],  # four layers\n","            5: [64, 128, 256, 512, 1024]  # five layers\n","#             5: [128, 256, 512, 1024, 512]  # five layers\n","        }\n","        return hidden_layers_configs[number]"]},{"cell_type":"markdown","metadata":{},"source":["# Train, Validate & Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.561638Z","iopub.status.busy":"2024-03-17T01:08:35.561067Z","iopub.status.idle":"2024-03-17T01:08:35.578295Z","shell.execute_reply":"2024-03-17T01:08:35.577546Z","shell.execute_reply.started":"2024-03-17T01:08:35.561607Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, train_dataloader, num_epochs, input_type, log_precision=False):\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","\n","        for sequences, pssms, labels in train_dataloader:\n","            if input_type == \"pssms\":\n","                inputs = pssms.permute(0, 2, 1)  # Adjust for PSSM data\n","            else:\n","                inputs = sequences.permute(0, 2, 1)  # Adjust for Sequence data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs.transpose(1, 2), labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # After each epoch, calculate precision\n","        all_predictions, all_labels = [], []\n","        model.eval()  # Set model to evaluation mode\n","        with torch.no_grad():\n","            for sequences, pssms, labels in train_dataloader:\n","#                 inputs = pssms.permute(0, 2, 1).cuda()  # Adjust for data and move to GPU\n","#                 labels = labels.cuda()\n","                inputs = pssms.permute(0, 2, 1)\n","                labels = labels\n","                outputs = model(inputs)\n","                _, predicted = torch.max(outputs.data, 2)\n","                all_predictions.extend(predicted.view(-1).cpu().numpy())\n","                all_labels.extend(labels.view(-1).cpu().numpy())\n","        \n","        # Calculate precision\n","        epoch_precision = precision_score(all_labels, all_predictions, average='macro')\n","        print(f'Epoch {epoch+1}/{num_epochs}, Precision: {epoch_precision:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.581363Z","iopub.status.busy":"2024-03-17T01:08:35.581123Z","iopub.status.idle":"2024-03-17T01:08:35.594476Z","shell.execute_reply":"2024-03-17T01:08:35.593819Z","shell.execute_reply.started":"2024-03-17T01:08:35.581343Z"},"trusted":true},"outputs":[],"source":["def validate_model(model, criterion, val_dataloader, input_type):\n","    model.eval()  # Set model to evaluation mode\n","    all_predictions, all_labels = [], []\n","\n","\n","    with torch.no_grad():\n","        for sequences, pssms, labels in val_dataloader:\n","            if input_type == \"pssms\":\n","                inputs = pssms.permute(0, 2, 1)  # Adjust for PSSM data\n","            else:\n","                inputs = sequences.permute(0, 2, 1)  # Adjust for PSSM data\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 2)\n","            \n","            all_predictions.extend(predicted.view(-1).cpu().numpy())\n","            all_labels.extend(labels.view(-1).cpu().numpy())\n","\n","    val_precision = precision_score(all_labels, all_predictions, average='macro')\n","    return val_precision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.595674Z","iopub.status.busy":"2024-03-17T01:08:35.595436Z","iopub.status.idle":"2024-03-17T01:08:35.611762Z","shell.execute_reply":"2024-03-17T01:08:35.610987Z","shell.execute_reply.started":"2024-03-17T01:08:35.595653Z"},"trusted":true},"outputs":[],"source":["def test_model_direct(model, test_dataset, output_file, input_type):\n","    model.eval()  # Set the model to evaluation mode\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for i in range(len(test_dataset)):  # Iterate directly over the dataset\n","            pdb_id, sequence, pssm = test_dataset[i]  # Assuming the dataset returns PDB_ID, sequence, and PSSM\n","\n","            # Prepare the input tensor; add an extra batch dimension using unsqueeze\n","            if input_type == \"pssms\":\n","                input = pssm.unsqueeze(0).permute(0, 2, 1)  # Adjust dimensions to [1, features, seq_len]\n","            else:\n","                input = sequence.unsqueeze(0).permute(0, 2, 1)  # Adjust dimensions to [1, features, seq_len]\n","            \n","            # Make a prediction\n","            outputs = model(input)\n","            _, predicted = torch.max(outputs, 2)  # Get the index of max log-probability\n","\n","            # Process the predictions\n","            seq_len = pssm.shape[0]  # Assuming pssm is [features, seq_len]\n","            for j in range(seq_len):\n","                residue_id = f\"{pdb_id}_{j + 1}\"  # Construct the ID\n","                structure_label = ['H', 'E', 'C'][predicted[0, j].item()]  # Map numeric predictions to labels\n","                predictions.append([residue_id, structure_label])\n","\n","    # Write predictions to CSV\n","    pd.DataFrame(predictions, columns=['ID', 'STRUCTURE']).to_csv(output_file, index=False)\n","    print(f'Submission file saved to {output_file}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.613171Z","iopub.status.busy":"2024-03-17T01:08:35.612869Z","iopub.status.idle":"2024-03-17T01:08:35.628636Z","shell.execute_reply":"2024-03-17T01:08:35.627956Z","shell.execute_reply.started":"2024-03-17T01:08:35.613148Z"},"trusted":true},"outputs":[],"source":["def get_optimizer(optimizer_type, model, lr, weight_decay):\n","    # Choose the optimizer based on the parameterization\n","    if optimizer_type == \"adam\":\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    elif optimizer_type == \"sgd\":\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","    elif optimizer_type == \"rmsprop\":\n","        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    else:\n","        raise ValueError(\"Unknown optimizer\")\n","\n","    return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.629990Z","iopub.status.busy":"2024-03-17T01:08:35.629731Z","iopub.status.idle":"2024-03-17T01:08:35.646390Z","shell.execute_reply":"2024-03-17T01:08:35.645733Z","shell.execute_reply.started":"2024-03-17T01:08:35.629967Z"},"trusted":true},"outputs":[],"source":["def train_validate_cv(\n","        num_folds,\n","        input_type,\n","        lr,\n","        batch_size,\n","        hidden_layers,\n","        dropout_rate,\n","        weight_decay,\n","        optimizer_type,\n","        normalization,\n","        num_epochs,\n","):\n","    train_dataset = ProteinDataset(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path,\n","                                   normalize_method=normalization)\n","\n","    # Initialize KFold\n","    kf = KFold(n_splits=num_folds)\n","\n","    # Convert entire dataset to a list for easier handling\n","    full_dataset_list = list(range(len(train_dataset)))  # Assumes dataset is your ProteinDataset instance\n","\n","    # Initialize lists to store results for each fold\n","    fold_precisions = []\n","    \n","    # Cross-validation loop\n","    for fold, (train_index, val_index) in enumerate(kf.split(full_dataset_list)):\n","        print(f\"Fold {fold + 1}/{num_folds}\")\n","\n","        # Split dataset\n","        train_subsampler = torch.utils.data.SubsetRandomSampler(train_index)\n","        val_subsampler = torch.utils.data.SubsetRandomSampler(val_index)\n","\n","        # Create data loaders for training and validation\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_subsampler, collate_fn=collate_fn)\n","        val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_subsampler, collate_fn=collate_fn)\n","\n","        # Initialize model\n","        if input_type == \"pssms\":\n","            input_channels = 20\n","        else:\n","            input_channels = 25\n","        model = FullyConvolutionalProteinModel(\n","            num_classes=3,\n","            input_channels=input_channels,\n","            hidden_layers_number=hidden_layers,\n","            dropout_rate=dropout_rate\n","        )\n","        \n","        if torch.cuda.device_count() > 1:\n","            print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n","            model = torch.nn.DataParallel(model)\n","\n","        model = model.to(device)\n","\n","        # Initialize loss function and optimizer\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = get_optimizer(optimizer_type, model, lr, weight_decay)\n","\n","        # Train and validate the model\n","        train_model(model, criterion, optimizer, train_loader, num_epochs, input_type)\n","        fold_precision = validate_model(model, criterion, val_loader, input_type)\n","        \n","        fold_precisions.append(fold_precision)\n","\n","    # Calculate average loss and accuracy across all folds\n","    avg_precisions = sum(fold_precisions) / num_folds\n","    print(f\"Average Precisions: {avg_precisions:.4f}\")\n","    return avg_precisions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.647737Z","iopub.status.busy":"2024-03-17T01:08:35.647418Z","iopub.status.idle":"2024-03-17T01:08:35.664740Z","shell.execute_reply":"2024-03-17T01:08:35.663914Z","shell.execute_reply.started":"2024-03-17T01:08:35.647709Z"},"trusted":true},"outputs":[],"source":["def train_test_full_data(\n","        input_type,\n","        lr,\n","        batch_size,\n","        hidden_layers,\n","        dropout_rate,\n","        weight_decay,\n","        optimizer_type,\n","        normalization,\n","        num_epochs,\n","        output_file\n","):\n","    print(\"Reading data\")\n","    train_dataset = ProteinDataset(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path,\n","                                   normalize_method=normalization)\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    test_dataset = ProteinDataset(csv_file=seqs_test_path, train_dir=test_path, normalize_method=normalization)\n","\n","    print(\"Initializing model\")\n","    if input_type == \"pssms\":\n","        input_channels = 20\n","    else:\n","        input_channels = 25\n","\n","    model = FullyConvolutionalProteinModel(\n","        num_classes=3,\n","        input_channels=input_channels,\n","        hidden_layers_number=hidden_layers,\n","        dropout_rate=dropout_rate\n","    )\n","\n","#     if torch.cuda.device_count() > 1:\n","#         print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n","#         model = torch.nn.DataParallel(model)\n","    \n","#     model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = get_optimizer(optimizer_type, model, lr, weight_decay)\n","\n","    print(\"Training model\")\n","    train_model(model, criterion, optimizer, train_dataloader, num_epochs, input_type)\n","    print(\"Testing model\")\n","    test_model_direct(model, test_dataset, output_file, input_type)"]},{"cell_type":"markdown","metadata":{},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.666200Z","iopub.status.busy":"2024-03-17T01:08:35.665873Z","iopub.status.idle":"2024-03-17T01:08:35.679641Z","shell.execute_reply":"2024-03-17T01:08:35.678807Z","shell.execute_reply.started":"2024-03-17T01:08:35.666168Z"},"trusted":true},"outputs":[],"source":["# train_validate_cv(\n","#     num_folds=3,\n","#     input_type=\"pssms\",  # \"sequence\" or \"pssms\"\n","#     lr=0.001,\n","#     batch_size=4,\n","#     hidden_layers=3,\n","#     dropout_rate=0.233246,\n","#     weight_decay=0.0,\n","#     optimizer_type='rmsprop',\n","#     normalization='min-max',\n","#     num_epochs=10,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.680914Z","iopub.status.busy":"2024-03-17T01:08:35.680614Z","iopub.status.idle":"2024-03-17T01:08:35.690411Z","shell.execute_reply":"2024-03-17T01:08:35.689604Z","shell.execute_reply.started":"2024-03-17T01:08:35.680881Z"},"trusted":true},"outputs":[],"source":["# train_test_full_data(\n","#     input_type=\"pssms\",  # \"sequence\" or \"pssms\"\n","#     lr=0.001,\n","#     batch_size=4,\n","#     hidden_layers=3,\n","#     dropout_rate=0.5,\n","#     weight_decay=0.0001,\n","#     optimizer_type='sgd',\n","#     normalization='min-max',\n","#     num_epochs=10,\n","#     output_file='./ax6/submission.csv'\n","# )"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter Tuning: ax_client"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:35.691914Z","iopub.status.busy":"2024-03-17T01:08:35.691569Z","iopub.status.idle":"2024-03-17T01:08:53.075102Z","shell.execute_reply":"2024-03-17T01:08:53.073988Z","shell.execute_reply.started":"2024-03-17T01:08:35.691883Z"},"trusted":true},"outputs":[],"source":["!pip install ax-platform"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:53.077519Z","iopub.status.busy":"2024-03-17T01:08:53.076669Z","iopub.status.idle":"2024-03-17T01:08:59.739278Z","shell.execute_reply":"2024-03-17T01:08:59.738559Z","shell.execute_reply.started":"2024-03-17T01:08:53.077480Z"},"trusted":true},"outputs":[],"source":["from ax.service.ax_client import AxClient\n","from ax.service.utils.instantiation import ObjectiveProperties\n","\n","import os\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch._tensor import Tensor\n","from ax.service.ax_client import AxClient, ObjectiveProperties\n","from ax.service.utils.report_utils import exp_to_df\n","from ax.utils.notebook.plotting import init_notebook_plotting, render\n","from ax.utils.tutorials.cnn_utils import evaluate, load_mnist, train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:59.740849Z","iopub.status.busy":"2024-03-17T01:08:59.740394Z","iopub.status.idle":"2024-03-17T01:08:59.745058Z","shell.execute_reply":"2024-03-17T01:08:59.744208Z","shell.execute_reply.started":"2024-03-17T01:08:59.740820Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:59.746841Z","iopub.status.busy":"2024-03-17T01:08:59.746528Z","iopub.status.idle":"2024-03-17T01:08:59.758852Z","shell.execute_reply":"2024-03-17T01:08:59.757951Z","shell.execute_reply.started":"2024-03-17T01:08:59.746816Z"},"trusted":true},"outputs":[],"source":["def train_evaluate(parameterization):\n","    avg_precision = train_validate_cv(\n","                                num_folds=3,\n","                                input_type=\"pssms\",  # \"sequence\" or \"pssms\"\n","                                lr=parameterization[\"lr\"],\n","                                batch_size=parameterization[\"batch_size\"],\n","                                hidden_layers=parameterization.get(\"hidden_layers\", 3),\n","                                dropout_rate=parameterization.get(\"dropout_rate\", 0.5),\n","                                weight_decay=parameterization.get(\"weight_decay\", 0),\n","                                optimizer_type=parameterization[\"optimizer\"],\n","                                normalization=parameterization[\"normalization\"],\n","                                num_epochs=parameterization.get(\"epochs\", 10),\n","                            )\n","    return {\"precision\": avg_precision}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T01:08:59.760157Z","iopub.status.busy":"2024-03-17T01:08:59.759888Z","iopub.status.idle":"2024-03-17T01:09:23.199239Z","shell.execute_reply":"2024-03-17T01:09:23.197736Z","shell.execute_reply.started":"2024-03-17T01:08:59.760133Z"},"trusted":true},"outputs":[],"source":["# Set up the Ax experiment\n","ax_client = AxClient(enforce_sequential_optimization=False)\n","ax_client.create_experiment(\n","    name=\"protein_model_experiment\",\n","    parameters=[\n","        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [0.0001, 0.01], \"log_scale\": True},\n","        {\"name\": \"batch_size\", \"type\": \"fixed\", \"value\": 4},\n","        {\"name\": \"hidden_layers\", \"type\": \"choice\", \"values\": [4, 5]},\n","        {\"name\": \"dropout_rate\", \"type\": \"range\", \"bounds\": [0.0, 0.7]},\n","        {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [0.0, 0.1]},\n","        {\"name\": \"epochs\", \"type\": \"fixed\", \"value\": 10},  # Fixed for all trials, can be changed as needed\n","        {\"name\": \"optimizer\", \"type\": \"fixed\", \"value\": \"rmsprop\"},  # Add optimizer as a choice\n","        {\"name\": \"normalization\", \"type\": \"fixed\", \"value\": \"min-max\"},\n","\n","    ],\n","#     parameters=[\n","#         {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [0.0001, 0.01], \"log_scale\": True},\n","#         {\"name\": \"batch_size\", \"type\": \"choice\", \"values\": [4, 16, 32, 64, 128]},\n","#         {\"name\": \"hidden_layers\", \"type\": \"choice\", \"values\": [2, 3, 4, 5]},\n","#         {\"name\": \"dropout_rate\", \"type\": \"range\", \"bounds\": [0.0, 0.7]},\n","#         {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [0.0, 0.1]},\n","#         {\"name\": \"epochs\", \"type\": \"fixed\", \"value\": 10},  # Fixed for all trials, can be changed as needed\n","#         {\"name\": \"optimizer\", \"type\": \"choice\", \"values\": [\"adam\", \"sgd\", \"rmsprop\"]},  # Add optimizer as a choice\n","#         {\"name\": \"normalization\", \"type\": \"choice\", \"values\": [\"min-max\", \"z-score\"]},  # Add optimizer as a choice\n","\n","#     ],\n","    objectives={\"precision\": ObjectiveProperties(minimize=False)}\n",")\n","\n","# Running the trials\n","for i in range(20):  # Number of iterations\n","    params, trial_index = ax_client.get_next_trial()\n","    metrics = train_evaluate(params)\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=metrics)\n","\n","# Fetch the best parameters\n","best_parameters, metrics = ax_client.get_best_parameters()\n","print(f'Best Parameters: {best_parameters}')\n","print(metrics)\n","best_metrics = metrics['objectives']\n","print(f'Best Precision: {best_metrics}')"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Selection"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7709659,"sourceId":68978,"sourceType":"competition"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
