{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T20:02:41.052017Z","iopub.status.busy":"2024-03-07T20:02:41.051626Z","iopub.status.idle":"2024-03-07T20:02:41.057817Z","shell.execute_reply":"2024-03-07T20:02:41.056802Z","shell.execute_reply.started":"2024-03-07T20:02:41.051987Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["# Imports & Packages"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T20:02:41.060352Z","iopub.status.busy":"2024-03-07T20:02:41.059999Z","iopub.status.idle":"2024-03-07T20:02:53.706671Z","shell.execute_reply":"2024-03-07T20:02:53.705340Z","shell.execute_reply.started":"2024-03-07T20:02:41.060322Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ipywidgets in /home/alex/anaconda3/lib/python3.11/site-packages (8.1.2)\n","Requirement already satisfied: comm>=0.1.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets) (8.15.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n","Requirement already satisfied: backcall in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: decorator in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: matplotlib-inline in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n","Requirement already satisfied: pickleshare in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n","Requirement already satisfied: pygments>=2.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n","Requirement already satisfied: stack-data in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/alex/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: executing in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n","Requirement already satisfied: asttokens in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n","Requirement already satisfied: pure-eval in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n","Requirement already satisfied: six in /home/alex/anaconda3/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"]}],"source":["!pip install -U ipywidgets"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T20:02:53.730017Z","iopub.status.busy":"2024-03-07T20:02:53.729625Z","iopub.status.idle":"2024-03-07T20:02:53.736756Z","shell.execute_reply":"2024-03-07T20:02:53.735900Z","shell.execute_reply.started":"2024-03-07T20:02:53.729990Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","\n","import numpy as np\n","import pandas as pd\n","import ray\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from ray import train as ray_train\n","from ray import tune\n","from ray.tune.schedulers import ASHAScheduler\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader, random_split"]},{"cell_type":"markdown","metadata":{},"source":["# Constants"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"f635a9cf-9b56-41c1-b423-38e13f72b067","_uuid":"83f50fc9-895b-4a81-8b08-f0da6d5fa4ac","collapsed":false,"execution":{"iopub.execute_input":"2024-03-07T20:02:53.738065Z","iopub.status.busy":"2024-03-07T20:02:53.737787Z","iopub.status.idle":"2024-03-07T20:02:53.747652Z","shell.execute_reply":"2024-03-07T20:02:53.746816Z","shell.execute_reply.started":"2024-03-07T20:02:53.738043Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Define Constants\n","\n","DATA_PATH = \"/kaggle/input/deep-learning-for-msc-202324/\"\n","labels_train_path = DATA_PATH + \"labels_train.csv\"\n","sample_path = DATA_PATH + \"sample.csv\"\n","seqs_test_path = DATA_PATH + \"seqs_test.csv\"\n","seqs_train_path = DATA_PATH + \"seqs_train.csv\"\n","train_path = DATA_PATH + \"train\"\n","test_path = DATA_PATH + \"test\"\n","\n","# Define a mapping from amino acid characters to integers\n","amino_acid_mapping = {\n","    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,\n","    'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,\n","    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,\n","    'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,\n","    'X': 20,  # Typically used for unknown amino acids\n","    'B': 21,  # Asparagine or Aspartic acid\n","    'Z': 22,  # Glutamine or Glutamic acid\n","    'J': 23,  # Leucine or Isoleucine\n","    '-': 24,  # Gap or padding\n","}\n","\n","sec_struct_mapping = {'H': 0, 'E': 1, 'C': 2}"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Class & Utils"]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"32ac1407-65f5-4381-8c33-b42d88efd856","_uuid":"de446eba-91c9-4920-b48e-dee1f3657699","collapsed":false,"execution":{"iopub.execute_input":"2024-03-07T20:02:53.749428Z","iopub.status.busy":"2024-03-07T20:02:53.748847Z","iopub.status.idle":"2024-03-07T20:02:53.767827Z","shell.execute_reply":"2024-03-07T20:02:53.766942Z","shell.execute_reply.started":"2024-03-07T20:02:53.749397Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class ProteinDataset(Dataset):\n","    def __init__(self, csv_file, train_dir, label_file=None, normalize_method='min-max'):\n","\n","        # Load the sequences\n","        self.seqs = pd.read_csv(csv_file)\n","\n","        # Load the protein data from the directory\n","        self.protein_data = {}\n","        for filename in os.listdir(train_dir):\n","            if filename.endswith(\".csv\"):  # Check if the file is a CSV\n","                protein_id = re.split(r'_train|_test', filename)[0]\n","                self.protein_data[protein_id] = pd.read_csv(os.path.join(train_dir, filename))\n","\n","        # Load the labels, if provided\n","        if label_file:\n","            self.labels = pd.read_csv(label_file)\n","        else:\n","            self.labels = None\n","\n","        # Amino acid mapping\n","        self.amino_acid_mapping = amino_acid_mapping\n","        self.normalize_method = normalize_method\n","\n","    def encode_sequence(self, sequence):\n","        # Convert each amino acid in the sequence to a one-hot encoded vector\n","        encoded_sequence = np.zeros((len(sequence), len(self.amino_acid_mapping)), dtype=int)\n","        for i, amino_acid in enumerate(sequence):\n","            # Default to 'X' for unknown amino acids\n","            index = self.amino_acid_mapping.get(amino_acid, self.amino_acid_mapping['X'])\n","            encoded_sequence[i, index] = 1\n","        return encoded_sequence\n","\n","    def normalize_pssm(self, pssm):\n","        # Assuming the first two columns are non-numeric; adjust as necessary based on your actual data format\n","        numeric_columns = pssm[:, 2:]  # Adjust this if your numeric data starts from a different column\n","\n","        # Convert to floats\n","        try:\n","            pssm_numeric = numeric_columns.astype(np.float32)\n","        except ValueError as e:\n","            # Handle or log the error if needed\n","            raise ValueError(f\"Error converting PSSM to float: {e}\")\n","\n","        if self.normalize_method == 'min-max':\n","            # Min-Max normalization\n","            pssm_min = pssm_numeric.min(axis=0)\n","            pssm_max = pssm_numeric.max(axis=0)\n","            # Ensure no division by zero\n","            pssm_range = np.where(pssm_max - pssm_min == 0, 1, pssm_max - pssm_min)\n","            normalized_pssm = (pssm_numeric - pssm_min) / pssm_range\n","        elif self.normalize_method == 'z-score':\n","            # Z-Score normalization\n","            pssm_mean = pssm_numeric.mean(axis=0)\n","            pssm_std = pssm_numeric.std(axis=0)\n","            # Avoid division by zero\n","            pssm_std = np.where(pssm_std == 0, 1, pssm_std)\n","            normalized_pssm = (pssm_numeric - pssm_mean) / pssm_std\n","        else:\n","            # If no normalization method provided, return the original PSSM\n","            normalized_pssm = pssm_numeric\n","\n","        return normalized_pssm\n","\n","    def __len__(self):\n","        return len(self.seqs)\n","\n","    def __getitem__(self, idx):\n","        protein_id = self.seqs.iloc[idx]['PDB_ID']\n","        sequence = self.seqs.iloc[idx]['SEQUENCE']\n","        encoded_sequence = self.encode_sequence(sequence)  # Encode the sequence\n","        pssm = self.protein_data[protein_id].values  # Assuming you will process PSSM separately\n","        normalized_pssm = self.normalize_pssm(pssm)  # Ensure this is uncommented to use normalized PSSM\n","\n","        if self.labels is not None:\n","            label_seq = self.labels.iloc[idx]['SEC_STRUCT']\n","            label_numeric = [sec_struct_mapping[char] for char in label_seq]\n","            label_tensor = torch.tensor(label_numeric, dtype=torch.long)\n","            return (\n","                protein_id,\n","                torch.tensor(encoded_sequence, dtype=torch.float32),\n","                torch.tensor(normalized_pssm, dtype=torch.float32),\n","                label_tensor\n","            )\n","\n","        return (\n","            protein_id,\n","            torch.tensor(encoded_sequence, dtype=torch.float32),\n","            torch.tensor(normalized_pssm, dtype=torch.float32)\n","        )\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def collate_fn(batch):\n","    _, sequences, pssms, labels_list = zip(*batch)  # Unzip the batch\n","\n","    # Pad sequences and PSSMs\n","    sequences_padded = pad_sequence([seq.clone().detach() for seq in sequences], batch_first=True)\n","\n","    pssms_padded = pad_sequence([pssm.clone().detach() for pssm in pssms], batch_first=True)\n","\n","    # Handling labels correctly\n","    if labels_list[0] is not None:  # Check if labels exist\n","        labels_padded = pad_sequence([label.clone().detach() for label in labels_list], batch_first=True)\n","\n","    else:\n","        labels_padded = None\n","\n","    # Create a mask based on the original sequence lengths\n","    mask = [torch.ones(len(label), dtype=torch.uint8) for label in labels_list]\n","    mask_padded = pad_sequence(mask, batch_first=True, padding_value=0)  # Assuming padding_value for labels is 0\n","    return sequences_padded, pssms_padded, labels_padded, mask_padded\n"]},{"cell_type":"markdown","metadata":{},"source":["# Fully Convolutional Networks (FCNs)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T20:02:53.795134Z","iopub.status.busy":"2024-03-07T20:02:53.794862Z","iopub.status.idle":"2024-03-07T20:02:53.807046Z","shell.execute_reply":"2024-03-07T20:02:53.806311Z","shell.execute_reply.started":"2024-03-07T20:02:53.795112Z"},"trusted":true},"outputs":[],"source":["class FullyConvolutionalProteinModel(nn.Module):\n","    def __init__(\n","            self, num_classes=3,\n","            input_channels=20,\n","            hidden_layers_number=3,\n","            dropout_rate=0.233246\n","    ):\n","        super(FullyConvolutionalProteinModel, self).__init__()\n","\n","        self.hidden_layers = self.get_hidden_layers_size(\n","            hidden_layers_number)  # List of out_channels for each hidden layer\n","        self.dropout_rate = dropout_rate\n","\n","        # Creating convolutional layers dynamically based on 'hidden_layers' input\n","        self.convs = nn.ModuleList()\n","        in_channels = input_channels\n","        for out_channels in self.hidden_layers:\n","            self.convs.append(\n","                nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n","            )\n","            in_channels = out_channels  # Next layer's in_channels is current layer's out_channels\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        # Final layer that maps to the number of classes\n","        # The last item of hidden_layers list is used as in_channels here\n","        self.final_conv = nn.Conv1d(in_channels=self.hidden_layers[-1], out_channels=num_classes, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Apply convolutional layers with activation functions and dropout\n","        for conv in self.convs:\n","            x = F.relu(conv(x))\n","            x = self.dropout(x)  # Apply dropout after activation\n","\n","        # Apply final convolutional layer - no activation, as CrossEntropyLoss includes it\n","        x = self.final_conv(x)\n","\n","        # No softmax here, as nn.CrossEntropyLoss applies it internally.\n","        # Transpose the output to match [batch_size, sequence_length, num_classes]\n","        x = x.transpose(1, 2)\n","\n","        return x\n","\n","    def get_hidden_layers_size(self, number):\n","        hidden_layers_configs = {\n","            1: [64],  # one layer with 64 channels\n","            2: [64, 128],  # two layers with 64 and 128 channels\n","            3: [64, 128, 256],  # three layers\n","            4: [64, 128, 256, 512],  # four layers\n","            5: [64, 128, 256, 512, 1024]  # five layers\n","        }\n","        return hidden_layers_configs[number]"]},{"cell_type":"markdown","metadata":{},"source":["# Train, Validate & Test"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def train_model(model, criterion, optimizer, train_dataloader, num_epochs=10):\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","        running_loss = 0.0\n","        correct_preds = 0\n","        total_preds = 0\n","\n","        for sequences, pssms, labels, _ in train_dataloader:\n","            inputs = pssms.permute(0, 2, 1)  # Adjust for PSSM data\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs.transpose(1, 2), labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            # Calculate training accuracy\n","            _, predicted = torch.max(outputs, 2)  # Get the index of the max log-probability\n","            correct_preds += (predicted == labels).sum().item()\n","            total_preds += labels.numel()\n","\n","        epoch_loss = running_loss / len(train_dataloader.dataset)\n","        epoch_acc = correct_preds / total_preds\n","        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def validate_model(model, criterion, val_dataloader):\n","    model.eval()  # Set model to evaluation mode\n","    running_loss = 0.0\n","    correct_preds = 0\n","    total_preds = 0\n","\n","    with torch.no_grad():\n","        for sequences, pssms, labels, _ in val_dataloader:\n","            inputs = pssms.permute(0, 2, 1)  # Adjust for PSSM data\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs.transpose(1, 2), labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs, 2)\n","            correct_preds += (predicted == labels).sum().item()\n","            total_preds += labels.numel()\n","\n","    val_loss = running_loss / len(val_dataloader.dataset)\n","    val_acc = correct_preds / total_preds\n","    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def test_model_direct(model, test_dataset, output_file='submission.csv'):\n","    model.eval()  # Set the model to evaluation mode\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for i in range(len(test_dataset)):  # Iterate directly over the dataset\n","            pdb_id, _, pssm = test_dataset[i]  # Assuming the dataset returns PDB_ID, sequence, and PSSM\n","\n","            # Prepare the input tensor; add an extra batch dimension using unsqueeze\n","            input_pssm = pssm.unsqueeze(0).permute(0, 2, 1)  # Adjust dimensions to [1, features, seq_len]\n","\n","            # Make a prediction\n","            outputs = model(input_pssm)\n","            _, predicted = torch.max(outputs, 2)  # Get the index of max log-probability\n","\n","            # Process the predictions\n","            seq_len = pssm.shape[0]  # Assuming pssm is [features, seq_len]\n","            for j in range(seq_len):\n","                residue_id = f\"{pdb_id}_{j + 1}\"  # Construct the ID\n","                structure_label = ['H', 'E', 'C'][predicted[0, j].item()]  # Map numeric predictions to labels\n","                predictions.append([residue_id, structure_label])\n","\n","    # Write predictions to CSV\n","    pd.DataFrame(predictions, columns=['ID', 'STRUCTURE']).to_csv(output_file, index=False)\n","    print(f'Submission file saved to {output_file}')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def get_optimizer(optimizer_type, model, lr, weight_decay):\n","    # Choose the optimizer based on the parameterization\n","    if optimizer_type == \"adam\":\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    elif optimizer_type == \"sgd\":\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","    elif optimizer_type == \"rmsprop\":\n","        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    else:\n","        raise ValueError(\"Unknown optimizer\")\n","\n","    return optimizer\n","\n","\n","def train_with_params(\n","        lr=0.001,\n","        batch_size=4,\n","        hidden_layers=5,\n","        dropout_rate=0.233246,\n","        weight_decay=0.0,\n","        optimizer='rmsprop',\n","        normalization='min-max',\n","        num_epochs=10,\n","        output_file='submission.csv'\n","):\n","    train_dataset = ProteinDataset(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path,\n","                                   normalize_method=normalization)\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    test_dataset = ProteinDataset(csv_file=seqs_test_path, train_dir=test_path, normalize_method=normalization)\n","\n","    # Splitting train_dataset into train and validation sets (adjust sizes as needed)\n","    train_size = int(0.8 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n","    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    model = FullyConvolutionalProteinModel(hidden_layers_number=hidden_layers, dropout_rate=dropout_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = get_optimizer(optimizer, model, lr, weight_decay)\n","\n","    train_model(model, criterion, optimizer, train_dataloader, num_epochs)\n","    validate_model(model, criterion, val_loader)\n","    test_model_direct(model, test_dataset, output_file)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter Tuning: ax_client"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ax-platform in /home/alex/anaconda3/lib/python3.11/site-packages (0.3.6)\n","Requirement already satisfied: botorch==0.9.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (0.9.5)\n","Requirement already satisfied: jinja2 in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (3.1.2)\n","Requirement already satisfied: pandas in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (2.0.3)\n","Requirement already satisfied: scipy in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (1.11.1)\n","Requirement already satisfied: scikit-learn in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (1.3.0)\n","Requirement already satisfied: ipywidgets in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (8.1.2)\n","Requirement already satisfied: plotly>=5.12.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (5.19.0)\n","Requirement already satisfied: typeguard in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (2.13.3)\n","Requirement already satisfied: pyre-extensions in /home/alex/anaconda3/lib/python3.11/site-packages (from ax-platform) (0.0.30)\n","Requirement already satisfied: multipledispatch in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (0.6.0)\n","Requirement already satisfied: torch>=1.13.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (2.2.0)\n","Requirement already satisfied: pyro-ppl>=1.8.4 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (1.8.6)\n","Requirement already satisfied: gpytorch==1.11 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (1.11)\n","Requirement already satisfied: linear-operator==0.5.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from botorch==0.9.5->ax-platform) (0.5.1)\n","Requirement already satisfied: jaxtyping>=0.2.9 in /home/alex/anaconda3/lib/python3.11/site-packages (from linear-operator==0.5.1->botorch==0.9.5->ax-platform) (0.2.25)\n","Requirement already satisfied: tenacity>=6.2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (8.2.2)\n","Requirement already satisfied: packaging in /home/alex/anaconda3/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (23.1)\n","Requirement already satisfied: comm>=0.1.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (8.15.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipywidgets->ax-platform) (3.0.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jinja2->ax-platform) (2.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from pandas->ax-platform) (1.24.3)\n","Requirement already satisfied: typing-inspect in /home/alex/anaconda3/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (0.9.0)\n","Requirement already satisfied: typing-extensions in /home/alex/anaconda3/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (4.9.0)\n","Requirement already satisfied: joblib>=1.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from scikit-learn->ax-platform) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from scikit-learn->ax-platform) (2.2.0)\n","Requirement already satisfied: backcall in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.2.0)\n","Requirement already satisfied: decorator in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.18.1)\n","Requirement already satisfied: matplotlib-inline in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.1.6)\n","Requirement already satisfied: pickleshare in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (3.0.36)\n","Requirement already satisfied: pygments>=2.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (2.15.1)\n","Requirement already satisfied: stack-data in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (4.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (3.3.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (0.1.2)\n","Requirement already satisfied: tqdm>=4.36 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.9.5->ax-platform) (4.65.0)\n","Requirement already satisfied: six>=1.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ax-platform) (1.16.0)\n","Requirement already satisfied: filelock in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (3.9.0)\n","Requirement already satisfied: sympy in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (1.11.1)\n","Requirement already satisfied: networkx in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (3.1)\n","Requirement already satisfied: fsspec in /home/alex/anaconda3/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.9.5->ax-platform) (2023.4.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from typing-inspect->pyre-extensions->ax-platform) (1.0.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->ax-platform) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->ax-platform) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/alex/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.5)\n","Requirement already satisfied: executing in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (0.8.3)\n","Requirement already satisfied: asttokens in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (2.0.5)\n","Requirement already satisfied: pure-eval in /home/alex/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /home/alex/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13.1->botorch==0.9.5->ax-platform) (1.3.0)\n"]}],"source":["!pip install ax-platform"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T20:03:06.582455Z","iopub.status.busy":"2024-03-07T20:03:06.582158Z","iopub.status.idle":"2024-03-07T20:03:52.502247Z","shell.execute_reply":"2024-03-07T20:03:52.500780Z","shell.execute_reply.started":"2024-03-07T20:03:06.582433Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[INFO 03-14 01:24:40] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter batch_size. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`is_ordered` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n","\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`sort_values` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n","\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_layers. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`is_ordered` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n","\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`sort_values` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n","\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter dropout_rate. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter weight_decay. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.STRING for parameter optimizer. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`is_ordered` is not specified for `ChoiceParameter` \"optimizer\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n","\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`sort_values` is not specified for `ChoiceParameter` \"optimizer\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n","\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Inferred value type of ParameterType.STRING for parameter normalization. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`is_ordered` is not specified for `ChoiceParameter` \"normalization\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n","\n","/home/alex/anaconda3/lib/python3.11/site-packages/ax/core/parameter.py:518: UserWarning:\n","\n","`sort_values` is not specified for `ChoiceParameter` \"normalization\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n","\n","[INFO 03-14 01:24:40] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[0.0001, 0.01], log_scale=True), ChoiceParameter(name='batch_size', parameter_type=INT, values=[16, 32, 64, 128], is_ordered=True, sort_values=True), ChoiceParameter(name='hidden_layers', parameter_type=INT, values=[2, 3, 4, 5], is_ordered=True, sort_values=True), RangeParameter(name='dropout_rate', parameter_type=FLOAT, range=[0.0, 0.7]), RangeParameter(name='weight_decay', parameter_type=FLOAT, range=[0.0, 0.1]), FixedParameter(name='epochs', parameter_type=INT, value=10), ChoiceParameter(name='optimizer', parameter_type=STRING, values=['adam', 'sgd', 'rmsprop'], is_ordered=False, sort_values=False), ChoiceParameter(name='normalization', parameter_type=STRING, values=['min-max', 'z-score'], is_ordered=False, sort_values=False)], parameter_constraints=[]).\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there are more ordered parameters than there are categories for the unordered categorical parameters.\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=7 num_trials=None use_batch_trials=False\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=14\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=14\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n","[INFO 03-14 01:24:40] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 14 trials, BoTorch for subsequent trials]). Iterations after 14 will take longer to generate due to model-fitting.\n","[WARNING 03-14 01:24:40] ax.modelbridge.generation_node: Even though this node is not flagged for generation of unlimited trials, there are no generation blocking criterion, therefore, unlimited trials will be generated.\n","[INFO 03-14 01:24:40] ax.service.ax_client: Generated new trial 0 with parameters {'lr': 0.002306, 'batch_size': 64, 'hidden_layers': 5, 'dropout_rate': 0.154269, 'weight_decay': 0.040836, 'optimizer': 'rmsprop', 'normalization': 'z-score', 'epochs': 10}.\n"]},{"ename":"TypeError","evalue":"FullyConvolutionalProteinModel.__init__() got an unexpected keyword argument 'hidden_layers'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):  \u001b[38;5;66;03m# Number of iterations\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     params, trial_index \u001b[38;5;241m=\u001b[39m ax_client\u001b[38;5;241m.\u001b[39mget_next_trial()\n\u001b[0;32m---> 88\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m train_evaluate(params)\n\u001b[1;32m     89\u001b[0m     ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(trial_index\u001b[38;5;241m=\u001b[39mtrial_index, raw_data\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Fetch the best parameters\u001b[39;00m\n","Cell \u001b[0;32mIn[17], line 33\u001b[0m, in \u001b[0;36mtrain_evaluate\u001b[0;34m(parameterization)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Inside your train_evaluate function\u001b[39;00m\n\u001b[1;32m     31\u001b[0m hidden_layers_structure \u001b[38;5;241m=\u001b[39m hidden_layers_configs[parameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m FullyConvolutionalProteinModel(\n\u001b[1;32m     34\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m     35\u001b[0m     input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     36\u001b[0m     hidden_layers\u001b[38;5;241m=\u001b[39mhidden_layers_structure,  \u001b[38;5;66;03m# Default to 2 if not specified\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39mparameterization\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Default to 0.5 if not specified\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Choose the optimizer based on the parameterization\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: FullyConvolutionalProteinModel.__init__() got an unexpected keyword argument 'hidden_layers'"]}],"source":["from ax.service.ax_client import AxClient\n","from ax.service.utils.instantiation import ObjectiveProperties\n","\n","import os\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch._tensor import Tensor\n","from ax.service.ax_client import AxClient, ObjectiveProperties\n","from ax.service.utils.report_utils import exp_to_df\n","from ax.utils.notebook.plotting import init_notebook_plotting, render\n","from ax.utils.tutorials.cnn_utils import evaluate, load_mnist, train\n","\n","\n","\n","def train_evaluate(parameterization):\n","    # Initialize your model with hyperparameters\n","    \n","    # This is an example mapping, adjust according to your needs\n","    hidden_layers_configs = {\n","        1: [64],  # one layer with 64 channels\n","        2: [64, 128],  # two layers with 64 and 128 channels\n","        3: [64, 128, 256],  # three layers\n","        4: [64, 128, 256, 512],  # four layers\n","        5: [64, 128, 256, 512, 1024]  # five layers\n","    }\n","\n","    # Inside your train_evaluate function\n","    hidden_layers_structure = hidden_layers_configs[parameterization.get(\"hidden_layers\", 2)]\n","\n","    model = FullyConvolutionalProteinModel(\n","        num_classes=3, \n","        input_channels=20,\n","        hidden_layers=hidden_layers_structure,  # Default to 2 if not specified\n","        dropout_rate=parameterization.get(\"dropout_rate\", 0.5)  # Default to 0.5 if not specified\n","    )\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Choose the optimizer based on the parameterization\n","    if parameterization[\"optimizer\"] == \"adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=parameterization[\"lr\"], weight_decay=parameterization.get(\"weight_decay\", 0))\n","    elif parameterization[\"optimizer\"] == \"sgd\":\n","        optimizer = optim.SGD(model.parameters(), lr=parameterization[\"lr\"], momentum=0.9, weight_decay=parameterization.get(\"weight_decay\", 0))\n","    elif parameterization[\"optimizer\"] == \"rmsprop\":\n","        optimizer = optim.RMSprop(model.parameters(), lr=parameterization[\"lr\"], weight_decay=parameterization.get(\"weight_decay\", 0))\n","    else:\n","        raise ValueError(\"Unknown optimizer\")\n","        \n","        \n","    dataset = ProteinDataset(csv_file=seqs_train_path, train_dir=train_path, label_file=labels_train_path, normalize_method=parameterization[\"normalization\"])\n","    train_size = int(0.8 * len(dataset))\n","    val_size = len(dataset) - train_size\n","    train_subset, val_subset = random_split(dataset, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_subset, batch_size=int(parameterization[\"batch_size\"]), shuffle=True, collate_fn=collate_fn)\n","    val_loader = DataLoader(val_subset, batch_size=int(parameterization[\"batch_size\"]), shuffle=False, collate_fn=collate_fn)\n","    \n","    # Your training and validation loop\n","    for epoch in range(parameterization.get(\"epochs\", 10)):  # Use the epochs parameter, default to 10\n","        train_model(model, criterion, optimizer, train_loader)  # Assume implementation\n","        val_loss, val_acc = validate_model(model, criterion, val_loader)  # Assume implementation\n","    \n","    return {\"accuracy\": val_acc, \"loss\": -val_loss}\n","\n","# Set up the Ax experiment\n","ax_client = AxClient(enforce_sequential_optimization=False)\n","ax_client.create_experiment(\n","    name=\"protein_model_experiment\",\n","    parameters=[\n","        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [0.0001, 0.01], \"log_scale\": True},\n","        {\"name\": \"batch_size\", \"type\": \"choice\", \"values\": [16, 32, 64, 128]},\n","        {\"name\": \"hidden_layers\", \"type\": \"choice\", \"values\": [2, 3, 4, 5]},\n","        {\"name\": \"dropout_rate\", \"type\": \"range\", \"bounds\": [0.0, 0.7]},\n","        {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [0.0, 0.1]},\n","        {\"name\": \"epochs\", \"type\": \"fixed\", \"value\": 10},  # Fixed for all trials, can be changed as needed\n","        {\"name\": \"optimizer\", \"type\": \"choice\", \"values\": [\"adam\", \"sgd\", \"rmsprop\"]},  # Add optimizer as a choice\n","        {\"name\": \"normalization\", \"type\": \"choice\", \"values\": [\"min-max\", \"z-score\"]},  # Add optimizer as a choice\n","\n","    ],\n","    objectives={\"accuracy\": ObjectiveProperties(minimize=False)}\n",")\n","\n","# Running the trials\n","for i in range(30):  # Number of iterations\n","    params, trial_index = ax_client.get_next_trial()\n","    metrics = train_evaluate(params)\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=metrics)\n","\n","# Fetch the best parameters\n","best_parameters, metrics = ax_client.get_best_parameters()\n","best_metrics = metrics['objectives']\n","print(f'Best Parameters: {best_parameters}')\n","print(f'Best Accuracy: {best_metrics}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:44:54.998690Z","iopub.status.busy":"2024-03-09T14:44:54.998284Z","iopub.status.idle":"2024-03-09T14:46:16.246448Z","shell.execute_reply":"2024-03-09T14:46:16.245469Z","shell.execute_reply.started":"2024-03-09T14:44:54.998658Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.feature_selection import f_classif\n","from sklearn.preprocessing import LabelEncoder\n","\n","def load_data_in_batches(seqs_train_path, train_path, labels_train_path, batch_size=100):\n","    # Load sequence and label information\n","    seqs_df = pd.read_csv(seqs_train_path)\n","    labels_df = pd.read_csv(labels_train_path)\n","    labels_map = dict(zip(labels_df['PDB_ID'], labels_df['SEC_STRUCT']))\n","\n","    batch_pssms = []\n","    batch_labels = []\n","\n","    # Process in batches\n","    for batch_start in range(0, len(seqs_df), batch_size):\n","        for _, row in seqs_df.iloc[batch_start:batch_start + batch_size].iterrows():\n","            pdb_id = row['PDB_ID']\n","            seq_label = labels_map.get(pdb_id, None)\n","\n","            if seq_label:\n","                pssm_file = os.path.join(train_path, f\"{pdb_id}_train.csv\")\n","                if os.path.exists(pssm_file):\n","                    pssm_df = pd.read_csv(pssm_file, usecols=range(2, 22))\n","                    pssm_values = pssm_df.to_numpy()\n","                    for pssm_row in pssm_values:\n","                        batch_pssms.append(pssm_row)\n","                        batch_labels.append(seq_label)  # Assuming one label per sequence\n","\n","        # Perform feature selection on the batch\n","        encoded_labels = LabelEncoder().fit_transform(batch_labels)\n","        f_values, p_values = f_classif(batch_pssms, encoded_labels)\n","        \n","        # Log or store batch results for later analysis\n","        print(f\"Batch {batch_start // batch_size + 1}\")\n","        for i in range(len(f_values)):\n","            print(f\"Feature {i}: F-value = {f_values[i]:.3f}, p-value = {p_values[i]:.3f}\")\n","\n","        # Reset for next batch\n","        batch_pssms = []\n","        batch_labels = []\n","\n","# Usage\n","DATA_PATH = \"/kaggle/input/deep-learning-for-msc-202324/\"\n","load_data_in_batches(DATA_PATH + 'seqs_train.csv', DATA_PATH + 'train', DATA_PATH + 'labels_train.csv', batch_size=100)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7709659,"sourceId":68978,"sourceType":"competition"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
